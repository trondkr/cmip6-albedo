{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "import os\n",
    "import seaborn as sns\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from shapely.geometry import box, mapping\n",
    "import geopandas as gpd\n",
    "from matplotlib import cm\n",
    "import texttable\n",
    "from xclim import ensembles\n",
    "import global_land_mask\n",
    "import logging\n",
    "from CMIP6_ridgeplot import CMIP6_ridgeplot\n",
    "import CMIP6_area_calculations\n",
    "\n",
    "logging.getLogger('xclim').setLevel('ERROR')\n",
    "logging.getLogger('root').setLevel('ERROR')\n",
    "sns.set(font_scale=1.5, style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_180(ds):\n",
    " #   ds=ds.assign_coords(lat=ds.y)\n",
    "    return (ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180))).sortby('lon')\n",
    "\n",
    "def convert_time(ds):\n",
    "    if not ds.indexes[\"time\"].dtype in [\"datetime64[ns]\"]:\n",
    "\n",
    "        time_objects = ds.indexes['time'].to_datetimeindex() \n",
    "        ds=ds.assign_coords({\"time\": time_objects})                   \n",
    "        ds = xr.decode_cf(ds)\n",
    "        \n",
    "    return ds\n",
    "\n",
    "def create_land_ocean_mask(cmip6_grid: xr.Dataset) -> xr.DataArray:\n",
    "    print(\"[create_land_ocean_mask] Running create_land_ocean_mask\")\n",
    "    lon = cmip6_grid.lon.values\n",
    "    lat = cmip6_grid.lat.values\n",
    "    lon_180 = xr.where(lon > 180, lon - 360, lon)\n",
    "    lon_grid, lat_grid = np.meshgrid(lon_180, lat)\n",
    "\n",
    "    mask_data = global_land_mask.globe.is_ocean(lat_grid, lon_grid).astype(int)\n",
    "    #  mask_data[np.isnan(mask_data)] = np.nan\n",
    "\n",
    "    return xr.DataArray(mask_data, coords={'lat': lat, 'lon': lon},\n",
    "                        dims=['lat', 'lon'])\n",
    "\n",
    "\n",
    "def get_area_averaged_ds(fname, model, scenario, var_name, var_name_std, LME,frequency, models_dict):\n",
    "    \n",
    "    if os.path.exists(fname):\n",
    "        with xr.open_dataset(fname) as ds:\n",
    "            ds = convert_to_180(ds)\n",
    "            ds = ds.sel(time=slice(start_time,end_time))\n",
    "            ds = convert_time(ds)\n",
    "\n",
    "            ds_lme = get_data_within_LME(ds, var_name, LME, False)\n",
    "            ds_lme[var_name] = CMIP6_area_calculations.xr_add_cyclic_point(ds_lme[var_name])\n",
    "            ds_lme[var_name].attrs[\"long_name\"]=var_name\n",
    "            ds_lme[var_name_std] = CMIP6_area_calculations.xr_add_cyclic_point(ds_lme[var_name_std])\n",
    "\n",
    "            # Add land mask\n",
    "            ds_lme[\"mask\"] = create_land_ocean_mask(ds_lme)\n",
    "            ds_lme = ds_lme.where(ds_lme.mask == 1)\n",
    "\n",
    "            ds_lme[\"areacello\"] = CMIP6_area_calculations.calculate_areacello(ds_lme, var_name)\n",
    "            # Clip the area to the polygon - this also clips to the time varying var_name which results in\n",
    "            # time varying areacello variable that we can use to sum up the size of open water by\n",
    "            # looking at the annual mean.\n",
    "            # First we set all areas outside of the polygon to nan - which also now includes\n",
    "            # areacello which as part of the calculations actually covered the whole region (and\n",
    "            # not just the polygon).\n",
    "            print(\"1\",ds_lme)\n",
    "            ds_lme = xr.where(np.isnan(ds_lme[var_name]), np.nan, ds_lme)\n",
    "            print(\"2\",ds_lme)\n",
    "\n",
    "            # Then we remove the areas where par or uv is less than a minimum value to remove zeroes etc.\n",
    "            if var_name in [\"par_mean\"]:\n",
    "                ds_lme = xr.where(ds_lme[var_name]<1, np.nan, ds_lme)\n",
    "                print(\"3\",ds_lme)\n",
    "            elif var_name in [\"uvb_mean\"]:\n",
    "                ds_lme = xr.where(ds_lme[var_name]<0.001, np.nan, ds_lme)\n",
    "            total_area_lme = np.nansum(ds_lme[\"areacello\"].mean(dim=\"time\").values)\n",
    "            print(\"[calculate_areacello] Average total area {:,.2f} km2\".format(total_area_lme))\n",
    "\n",
    "            ds_lme = ds_lme.assign(openwater = (xr.where(np.isnan(ds_lme[var_name]),np.nan, ds_lme[\"areacello\"])))\n",
    "\n",
    "            # Average data within the LME as a function of time\n",
    "            ds = ds_lme.mean({\"lat\",\"lon\"})\n",
    "\n",
    "            # To get the average sum of the open water areas we sum prior to creating the\n",
    "            # dataframe. Then when running rolling mean we just get the summed value back smoothed.\n",
    "            ds = ds.assign(areacello = ds_lme[\"areacello\"].sum(dim={\"lat\",\"lon\"}, skipna=True))\n",
    "            ds = ds.assign(openwater = ds_lme[\"openwater\"].sum(dim={\"lat\",\"lon\"}, skipna=True))\n",
    "           # ds.to_netcdf(\"test.nc\")\n",
    "\n",
    "            df = ds.to_dataframe().dropna().reset_index()\n",
    "\n",
    "        roll_years=5\n",
    "        df=df.resample(\"A\", on=\"time\").mean()\n",
    "\n",
    "        df[\"model_name\"]=model\n",
    "        df[\"roll_mean\"]=df[var_name].rolling(roll_years).mean()\n",
    "        df[\"roll_std\"]=df[var_name_std].rolling(roll_years).mean()\n",
    "        df[\"roll_mean_area\"]=df[\"areacello\"].rolling(roll_years).mean()\n",
    "\n",
    "        df[\"roll_median\"]=df[var_name].rolling(roll_years).median()\n",
    "        df[\"model_scenario\"]=scenario\n",
    "        df[\"model_name_scenario\"]=model+\"_\"+scenario\n",
    "        unique=\"{}_{}\".format(model, scenario)\n",
    "        df[\"unique\"]=unique\n",
    "\n",
    "        model_info={}\n",
    "        model_info[\"model_name\"]=model\n",
    "        model_info[\"model_scenario\"]=scenario\n",
    "        model_info[\"model_var\"]=var_name\n",
    "        formatter=\"{:.2f}\"\n",
    "        model_info[\"model_min\"]=formatter.format(np.nanmin(df[var_name]))\n",
    "        model_info[\"model_max\"]=formatter.format(np.nanmax(df[var_name]))\n",
    "        return df, models_dict, ds_lme, total_area_lme\n",
    "    else:\n",
    "        return None, models_dict, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_LME_records():\n",
    "    lme_file='../oceanography/Shapefiles/LME66/LMEs66.shp'\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "def get_LME_records_plot():\n",
    "    lme_file='../oceanography/Shapefiles/LME66_180/LME66_180.shp'\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "def create_colors(N):\n",
    "    color=iter(cm.tab20b(np.linspace(0,1,N)))\n",
    "    return [next(color) for c in range(N)]\n",
    "\n",
    "\n",
    "def get_data_within_LME(ds,var_name,LME,create_maps):\n",
    "    print(\"Working on LME: {}\".format(LME))\n",
    "\n",
    "    # Extract the polygon defining the boundaries of the LME\n",
    "    shdf = get_LME_records()\n",
    "   # for name in shdf['LME_NAME']:\n",
    "   #     print(name)\n",
    "    shdf_sel = shdf[ shdf['LME_NAME']==LME ]\n",
    "\n",
    "    # Rioxarray requires x and y dimensions - we convert these back to lon and lat later.\n",
    "    # We also add the projection (lat-lon) so that rioxarray can do the clipping of the data according to the\n",
    "    # shapefile.\n",
    "    tos=ds.rename({'lon': 'x','lat': 'y'})\n",
    "    tos=tos.rio.write_crs(4326)\n",
    "\n",
    "    # Clip the data within the LME. We have to convert the polygon geometry to a geodataframe using\n",
    "    # `shapely.geometry`. The clipping of data within the polygon is done using rioxarray.clip function\n",
    "\n",
    "    clipped = tos.rio.clip(geometries=shdf_sel.geometry.apply(mapping), crs=tos.rio.crs)\n",
    "    clipped=clipped.rename({'x': 'lon','y': 'lat'}) #.to_dataset()\n",
    "\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_summary_table(dict_of_models, LME):\n",
    "    table = texttable.Texttable()\n",
    "    table.set_cols_align([\"c\",\"c\", \"c\",\"c\",\"c\",\"c\",\"c\"])\n",
    "    table.set_cols_valign([\"t\",\"t\", \"m\",\"m\",\"m\",\"m\", \"b\"])\n",
    "\n",
    "    table.header([\"LME\",\"Model\", \"Scenario\", \"ID\", \"Var\", \"CMIP6 min\", \"CMIP6 max\"])\n",
    "    for key in dict_of_models.keys():\n",
    "        model=dict_of_models[key]\n",
    "\n",
    "        table.add_row([LME,\n",
    "                       model[\"model_name\"],\n",
    "                       model[\"model_scenario\"],\n",
    "                       model[\"model_ensemble_id\"],\n",
    "                       str(model[\"model_var\"]),\n",
    "                       str(model[\"model_min\"]),\n",
    "                       str(model[\"model_max\"])])\n",
    "\n",
    "    table.set_cols_width([30,30,20,20,10,10,10])\n",
    "    print(table.draw() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "scenarios = [\"ssp245\", \"ssp585\"]\n",
    "member_range = 12\n",
    "frequency = \"A\"\n",
    "period = \"1979-01-01-2099-12-16\"\n",
    "start_time = \"1979-01-01\"\n",
    "end_time = \"2099-12-16\"\n",
    "\n",
    "models = [\"ensemble\"]\n",
    "ds_var_names = [\"par\"] #, \"uvb\", \"uv\"]\n",
    "#ds_var_names = [\"uv\",\"uvb\"]  #,\"uv\"]\n",
    "write_stats_to_file = False\n",
    "sns.set(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)}, font_scale=1.5)\n",
    "\n",
    "\n",
    "LMES = ['California Current', 'East Bering Sea', 'Gulf of Alaska',\n",
    "        'Northern Bering - Chukchi Seas', 'West Bering Sea', 'Sea of Japan',\n",
    "        'Oyashio Current', 'Kuroshio Current', 'East China Sea',\n",
    "        'South China Sea', 'Sea of Okhotsk', 'Yellow Sea',\n",
    "        'Aleutian Islands']\n",
    "\n",
    "LMES = ['Barents Sea', 'Northern Bering - Chukchi Seas']\n",
    "\n",
    "for var_name in ds_var_names:\n",
    "    for LME in LMES:\n",
    "        df_list = []\n",
    "        models_dict = {}\n",
    "        simulation = \"osa\"\n",
    "        create_maps = False\n",
    "        saved_total_area_lme = None\n",
    "        f = plt.figure(figsize=(10, 10))\n",
    "        gs = f.add_gridspec(1, 1)\n",
    "        ax = f.add_subplot(gs[0, 0])\n",
    "        sns.set_palette(\"tab10\")\n",
    "        loop=0\n",
    "        palette_tab10 = sns.color_palette(\"tab10\", 10)\n",
    "        colors = [palette_tab10[0], palette_tab10[1], palette_tab10[3]]\n",
    "\n",
    "        # We loop over all of the scenarios, ensemble_ids, and models to create a\n",
    "        # list of dataframes that we eventually concatenate together and plot\n",
    "        for scenario in scenarios:\n",
    "            fname = \"../oceanography/light/ncfiles/ensemble/{}_{}_{}.nc\".format(var_name,\n",
    "                                                                                         \"ensemble\",\n",
    "                                                                                         scenario)\n",
    "            if scenario==\"ssp585\":\n",
    "                label=\"SSP5-8.5\"\n",
    "            else:\n",
    "                label=\"SSP2-4.5\"\n",
    "            var_name_mean=f\"{var_name}_mean\"\n",
    "            var_name_std=f\"{var_name}_stdev\"\n",
    "            df, models_dict, ds_lme, total_area_lme = get_area_averaged_ds(fname,  \"ensemble\",\n",
    "                                                                           scenario,var_name_mean,var_name_std,\n",
    "                                                                           LME, frequency, models_dict)\n",
    "\n",
    "            if ds_lme is not None:\n",
    "                saved_total_area_lme = total_area_lme\n",
    "                ds_lme = xr.where(((ds_lme < 1.e-20) | (ds_lme > 1e20)), np.nan, ds_lme)\n",
    "\n",
    "            outfile = \"Figures/{}_ensemble_{}_{}.png\".format(var_name_mean.capitalize(), scenario, LME)\n",
    "           # CMIP6_ridgeplot.ridgeplot(\"{}_mean\".format(var_name),\n",
    "           #                           None, outfile,\n",
    "           #                                   glorys=False, depth_threshold=None,\n",
    "           #                                   ds=ens_stats)\n",
    "\n",
    "\n",
    "            if var_name_mean in [\"par_mean\",\"uvb_mean\", \"uv_mean\"]:\n",
    "                df[\"roll_mean\"] = df[\"roll_mean\"].apply(lambda x : x if x > 0 else np.nan)\n",
    "\n",
    "            clim = (df[\"roll_mean\"].loc['1980-01-01':'2000-01-01']).mean()\n",
    "            df[\"rel_change\"] = ((df[\"roll_mean\"] - float(clim)) / float(clim)) * 100.\n",
    "\n",
    "            ax.fill_between(df[\"roll_mean\"].index,\n",
    "                df[\"roll_mean\"]+df[\"roll_std\"], df[\"roll_mean\"]-df[\"roll_std\"],\n",
    "                alpha=0.2,\n",
    "                color=colors[loop],\n",
    "                label=None,\n",
    "            )\n",
    "\n",
    "            ax.plot(\n",
    "                df[\"roll_mean\"].index,\n",
    "                df[\"roll_mean\"],\n",
    "                linewidth=5,\n",
    "                color=colors[loop],\n",
    "                label=f\"{label}\",\n",
    "            )\n",
    "\n",
    "            ax.tick_params(labelsize=22)\n",
    "            ax.set_xlabel(\"\", fontsize=20)\n",
    "            ax.set_ylabel(\"\", fontsize=20)\n",
    "\n",
    "            if loop==0:\n",
    "                ax2 = ax.twinx()\n",
    "\n",
    "            ax2.plot(\n",
    "                df[\"rel_change\"].index,\n",
    "                df[\"rel_change\"],\n",
    "                linewidth=3,\n",
    "                linestyle=\"--\",\n",
    "                color=colors[loop],\n",
    "                label=None,\n",
    "            )\n",
    "\n",
    "            ax2.tick_params(labelsize=22)\n",
    "            ax2.set_xlabel(\"\", fontsize=20)\n",
    "            ax2.set_ylabel(\"\", fontsize=20)\n",
    "            ylabels = ['{:,.0%}'.format(y) for y in ax2.get_yticks() / 100.]\n",
    "            ax2.set_yticklabels(ylabels)\n",
    "            import matplotlib.dates as mdates\n",
    "            ax.xaxis.set_major_locator(mdates.YearLocator(base=10))\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "            plt.setp(ax.xaxis.get_majorticklabels(), rotation=-90)\n",
    "           # ax2.get_legend().remove()\n",
    "            ax.legend(loc=\"upper left\", frameon=False, fontsize=32)\n",
    "\n",
    "            if not os.path.exists(\"Figures\"):\n",
    "                os.makedirs(\"Figures\")\n",
    "\n",
    "            if loop==1:\n",
    "                plotfile = \"Figures/CMIP6_light_{}_{}.png\".format(var_name_mean, LME)\n",
    "                print(\"Created figure {}\".format(plotfile))\n",
    "                plt.savefig(plotfile, dpi=200,\n",
    "                            bbox_inches='tight')\n",
    "\n",
    "\n",
    "            # Plot individual figure the open water area\n",
    "\n",
    "            if var_name_mean in [\"par_mean\"]:\n",
    "                if loop==0:\n",
    "                    f2 = plt.figure(figsize=(16, 16))\n",
    "                    gs2 = f2.add_gridspec(1, 1)\n",
    "                    ax3 = f2.add_subplot(gs2[0, 0])\n",
    "\n",
    "                # Colors from deep default seaborn palette found here:\n",
    "                # https://github.com/mwaskom/seaborn/blob/master/seaborn/palettes.py\n",
    "                colors_water = [\"#8172B3\", \"#64B5CD\"]\n",
    "\n",
    "                # Add extra variable - percentage change in size of open water area.\n",
    "                df[\"change_open_water\"] = (df[\"roll_mean_area\"] / float(saved_total_area_lme)) * 100.\n",
    "\n",
    "                print(f\"Calculating for scenario: {scenario} {df.head(2)} loop {loop}\")\n",
    "                # Plot the results\n",
    "                # Note that we do not actually plot the roll_mean_area in axis ax2 only in ax3 below\n",
    "               # ax3.fill_between(df[\"change_open_water\"].index, df[\"change_open_water\"], df[\"change_open_water\"],\n",
    "               #     alpha=0.2,\n",
    "               #     color=colors_water[loop],\n",
    "               #     label=None,\n",
    "               #     )\n",
    "\n",
    "                ax3.plot(\n",
    "                    df[\"roll_mean_area\"].index,\n",
    "                    df[\"change_open_water\"],\n",
    "                    linewidth=5,\n",
    "                    color=colors[loop],\n",
    "                    label=f\"{label}\",\n",
    "                )\n",
    "\n",
    "                ax3.tick_params(labelsize=22)\n",
    "                ax3.set_xlabel(\"\", fontsize=20)\n",
    "                ax3.set_ylabel(\"\", fontsize=20)\n",
    "\n",
    "                # Format the yticks\n",
    "                # https://mkaz.blog/code/python-string-format-cookbook/\n",
    "                ylabels = ['{:,}'.format(y) for y in ax3.get_yticks()]\n",
    "                ax3.set_yticklabels(ylabels)\n",
    "\n",
    "            #    print(\"Open water calculations range from {} on {} to {} in {}\".format(df[\"change_open_water\"].iloc[0],\n",
    "            #                                                                           df.index.iloc[0],\n",
    "            #                                                                           df[\"change_open_water\"].iloc[-1],\n",
    "            #                                                                           df.index.iloc[-1]))\n",
    "\n",
    "                ax3.tick_params(labelsize=22)\n",
    "                ax3.set_xlabel(\"\", fontsize=20)\n",
    "                ax3.set_ylabel(\"\", fontsize=20)\n",
    "                ylabels = ['{:,.0%}'.format(y) for y in ax3.get_yticks() / 100.]\n",
    "                ax3.set_yticklabels(ylabels)\n",
    "\n",
    "                import matplotlib.dates as mdates\n",
    "                ax3.xaxis.set_major_locator(mdates.YearLocator(base=10))\n",
    "                ax3.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "                plt.setp(ax3.xaxis.get_majorticklabels(), rotation=-90)\n",
    "\n",
    "              #  ax3.get_legend().remove()\n",
    "                ax3.legend(loc=\"upper left\", frameon=False, fontsize=32)\n",
    "\n",
    "            loop+=1\n",
    "        plt.show()\n",
    "        if var_name in [\"par_mean\"]:\n",
    "            plotfile = \"Figures/CMIP6_light_{}_{}.png\".format(\"area_open_water\", LME)\n",
    "            print(\"Created figure {}\".format(plotfile))\n",
    "            plt.savefig(plotfile, dpi=300,bbox_inches='tight')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}