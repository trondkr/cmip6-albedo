{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import cdsapi\n",
    "import numpy as np\n",
    "import warnings\n",
    "import regionmask\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "import cftime\n",
    "import os, sys\n",
    "import seaborn as sns\n",
    "import cartopy\n",
    "import cartopy.feature as cpf\n",
    "from global_land_mask import globe\n",
    "import CMIP6_light_map\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from shapely.geometry import box, mapping\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "from matplotlib import cm\n",
    "import cartopy.feature as cpf\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import texttable\n",
    "from tqdm.notebook import trange, tqdm\n",
    "sys.path.append(\"../Farallon/QIN/CMIP6-downscale/\")\n",
    "from CMIP6_ridgeplot import CMIP6_ridgeplot\n",
    "from xclim import ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_180(ds):\n",
    "\n",
    "    ds=ds.assign_coords(lat=ds.y)\n",
    "    return (ds.assign_coords(lon=(((ds.x + 180) % 360) - 180))).sortby('lon')\n",
    "\n",
    "def convert_time(ds):\n",
    "    if not ds.indexes[\"time\"].dtype in [\"datetime64[ns]\"]:\n",
    "\n",
    "        time_objects = ds.indexes['time'].to_datetimeindex()\n",
    "        ds=ds.assign_coords({\"time\": time_objects})\n",
    "        ds = xr.decode_cf(ds)\n",
    "\n",
    "    return ds\n",
    "\n",
    "def get_area_averaged_ds(fname, model, scenario, ensemble_id, var_name, LME, create_maps, frequency, models_dict,fname2=None):\n",
    "\n",
    "    if os.path.exists(fname):\n",
    "\n",
    "        if var_name not in [\"velocity\"]:\n",
    "            with xr.open_dataset(fname) as ds:\n",
    "\n",
    "                if var_name in [\"TOZ\"]:\n",
    "                   # ds=ds.assign_coords(y=ds.lat, x=ds.lon)\n",
    "                    ds = (ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180))).sortby('lon')\n",
    "                else:\n",
    "                    ds = convert_to_180(ds)\n",
    "\n",
    "                ds = ds.sel(time=slice(start_time,end_time)) #.sel(lat=slice(min_lat,max_lat), lon=slice(min_lon,max_lon))\n",
    "                ds = convert_time(ds)\n",
    "                if var_name in [\"tas\"]:\n",
    "                    ds=xr.where(ds>100,ds-273.15,ds)\n",
    "\n",
    "                # Convert from kg/m-3 to mg/m-3\n",
    "                if var_name in [\"chl\"]:\n",
    "                    ds[var_name]=ds[var_name]/1.0e6\n",
    "\n",
    "                ds_lme = get_data_within_LME(ds, var_name, LME, create_maps)\n",
    "                ds = ds_lme.mean({\"lat\",\"lon\"})\n",
    "                df = ds.to_dataframe().dropna()\n",
    "\n",
    "                df = df.reset_index()\n",
    "\n",
    "        else:\n",
    "            with xr.open_mfdataset([fname,fname2]) as ds:\n",
    "\n",
    "                ds = convert_to_180(ds)\n",
    "                print(ds)\n",
    "                ds = ds.sel(time=slice(start_time,end_time)) #.sel(lat=slice(min_lat,max_lat), lon=slice(min_lon,max_lon))\n",
    "                ds = convert_time(ds)\n",
    "                ds_uas = get_data_within_LME(ds, \"uas\", LME, create_maps)\n",
    "                ds_vas = get_data_within_LME(ds, \"vas\", LME, create_maps)\n",
    "                ds_uas = ds_uas.mean({\"lat\",\"lon\"})\n",
    "                ds_vas = ds_vas.mean({\"lat\",\"lon\"})\n",
    "                df = ds_uas.to_dataframe().dropna()\n",
    "                df2 = ds_vas.to_dataframe().dropna()\n",
    "\n",
    "                df = df.reset_index()\n",
    "                df2 = df2.reset_index()\n",
    "\n",
    "                df[\"velocity\"]=np.sqrt(np.power(df[\"uas\"], 2)+np.power(df2[\"vas\"], 2))\n",
    "                df = df.reset_index()\n",
    "                df.drop(columns=[\"uas\",\"vas\"], inplace=True)\n",
    "\n",
    "        df=df.resample(frequency, on=\"time\").mean()\n",
    "        df[\"model_name\"]=model\n",
    "        df[\"LME\"]=LME\n",
    "        df[\"roll_mean\"]=df[var_name].rolling(5).mean().shift(-1)\n",
    "        df[\"roll_median\"]=df[var_name].rolling(5).median().shift(-1)\n",
    "        df[\"roll_max\"]=df[var_name].rolling(5).max().shift(-1)\n",
    "        df[\"roll_min\"]=df[var_name].rolling(5).min().shift(-1)\n",
    "\n",
    "        df[\"model_ensemble_id\"]=ensemble_id\n",
    "        df[\"model_scenario\"]=scenario\n",
    "        unique=\"{}_{}_{}\".format(model, scenario, ensemble_id)\n",
    "        df[\"unique\"]=unique\n",
    "\n",
    "        model_info={}\n",
    "        model_info[\"model_name\"]=model\n",
    "        model_info[\"model_scenario\"]=scenario\n",
    "        model_info[\"model_ensemble_id\"]=ensemble_id\n",
    "        model_info[\"model_var\"]=var_name\n",
    "        model_info[\"LME\"]=LME\n",
    "        key=\"{}_{}_{}_{}\".format(model,ensemble_id,scenario,var_name)\n",
    "        if var_name in [\"TOZ\"]:\n",
    "            key=fname\n",
    "\n",
    "        formatter=\"{:.2f}\"\n",
    "        model_info[\"model_min\"]=formatter.format(np.nanmin(df[var_name]))\n",
    "        model_info[\"model_max\"]=formatter.format(np.nanmax(df[var_name]))\n",
    "\n",
    "        models_dict[key]=model_info\n",
    "\n",
    "        return df, models_dict, None\n",
    "    else:\n",
    "        return None, models_dict, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_LME_records():\n",
    "    lme_file='../oceanography/Shapefiles/LME66/LMEs66.shp'\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "def get_LME_records_plot():\n",
    "    lme_file='../oceanography/Shapefiles/LME66_180/LME66_180.shp'\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "def create_colors(N):\n",
    "    color=iter(cm.tab20b(np.linspace(0,1,N)))\n",
    "    return [next(color) for c in range(N)]\n",
    "\n",
    "def create_map(df, title, var_name, period, anomalies=False, details=False):\n",
    "    if details is True:\n",
    "        lonmin=-165\n",
    "        lonmax=-143.5\n",
    "        latmin=53.5\n",
    "        latmax=65.0\n",
    "        res=\"10m\"\n",
    "    else:\n",
    "        lonmin=-252\n",
    "        lonmax=-100.5\n",
    "        latmin=20\n",
    "        latmax=80\n",
    "        res=\"50m\"\n",
    "    ax = plt.figure(figsize=(16,10)).gca(projection=cartopy.crs.PlateCarree(central_longitude=-180))\n",
    "\n",
    "    ax.coastlines(resolution=res, linewidth=0.6, color=\"black\", alpha=0.8, zorder=4)\n",
    "    ax.add_feature(cpf.BORDERS, linestyle=':',alpha=0.4)\n",
    "    ax.add_feature(cpf.LAND, color=\"lightgrey\")\n",
    "    ax.set_extent([lonmin, lonmax, latmin, latmax])\n",
    "\n",
    "    xticks = np.linspace(lonmin, lonmax, 5)\n",
    "    yticks = np.linspace(latmin, latmax, 5)\n",
    "\n",
    "    ax.set_xticks(xticks, crs=cartopy.crs.PlateCarree())\n",
    "    ax.set_yticks(yticks, crs=cartopy.crs.PlateCarree())\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)\n",
    "\n",
    "    #if var_name in [\"par\"]:\n",
    "    clb_label='PAR ($W/m^{2}$)'\n",
    "    cs=ax.contourf(df[\"lon\"], df[\"lat\"], df[var_name], #np.where(df[\"H\"] < 0, df[\"H\"], np.nan), # df[var_name],\n",
    "                   cmap=sns.color_palette(\"Spectral_r\", as_cmap=True),\n",
    "                   transform=ccrs.PlateCarree())\n",
    "\n",
    "    if title not in [\"Bathymetry\"]:\n",
    "        clb = plt.colorbar(cs, shrink=0.5, extend=\"both\")\n",
    "\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "\n",
    "    #if details:\n",
    "    #    plt.savefig(\"../../GOA-Laurel/Figures/Bottom_{}_july_sept_250m_zoomed_{}.png\".format(var_name, period), dpi=300,\n",
    "    #                facecolor='w',\n",
    "    #                transparent=False,\n",
    "    #                bbox_inches = 'tight',\n",
    "    #                pad_inches = 0)\n",
    "    #else:\n",
    "    #    plt.savefig(\"../../GOA-Laurel/Figures/Bottom_{}_july_sept_250m_{}.png\".format(var_name, period), dpi=300,\n",
    "    #            facecolor='w',\n",
    "    #                transparent=False,\n",
    "    #                bbox_inches = 'tight',\n",
    "    #                pad_inches = 0)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_LME_figure(ax, LMES, projection, show, extent):\n",
    "\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "    ax.set_extent(extent)\n",
    "\n",
    "    # Get the -180-180 projected shapefile containing LMEs to make it\n",
    "    # easy to plot across the Pacific Ocean\n",
    "    shdf = get_LME_records_plot()\n",
    "    colors_rgb=create_colors(len(LMES))\n",
    "    counter=0\n",
    "    for LME_NAME,LME_NUMBER in zip(shdf['LME_NAME'],shdf['LME_NUMBER']):\n",
    "\n",
    "        shdf_sel = shdf[ shdf['LME_NAME']==LME_NAME ]\n",
    "\n",
    "        if (LME_NAME in LMES):\n",
    "           # print(\"Adding geometry for LME {}\".format(LME_NAME))\n",
    "            # Add the geometry and fill it with color\n",
    "            if len(LMES)==1:\n",
    "                color=\"red\"\n",
    "            else:\n",
    "                color=colors_rgb[counter]\n",
    "            ax.add_geometries(shdf_sel['geometry'],\n",
    "                              projection,\n",
    "                              facecolor=color,\n",
    "                              edgecolor='k')\n",
    "\n",
    "            # Add the label LME_NUMBER of the selected LME at the center of the LME\n",
    "          #  ax.annotate(s=LME_NUMBER,\n",
    "          #              xy=(shdf_sel.centroid.x,shdf_sel.centroid.y),\n",
    "          #              color=\"white\",\n",
    "          #              fontsize=13)\n",
    "            counter+=1\n",
    "        else:\n",
    "            ax.add_geometries(shdf_sel['geometry'],\n",
    "                              projection,\n",
    "                              facecolor='LightGray',\n",
    "                              edgecolor='k')\n",
    "\n",
    "    if show:\n",
    "        plotfile=\"Figures/CMIP6_lightpaper_map_{}.png\".format(LMES[0])\n",
    "        print(\"Created figure {}\".format(plotfile))\n",
    "        plt.savefig(plotfile, dpi=200,\n",
    "                        bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "\n",
    "def get_data_within_LME(ds,var_name,LME,create_maps):\n",
    "\n",
    "    print(\"Working on LME: {}\".format(LME))\n",
    "\n",
    "    # Extract the polygon defining the boundaries of the LME\n",
    "    shdf = get_LME_records()\n",
    "   # for name in shdf['LME_NAME']:\n",
    "   #     print(name)\n",
    "    shdf_sel = shdf[ shdf['LME_NAME']==LME ]\n",
    "\n",
    "    # Create the map of the LME bopundaries and color it.\n",
    "    # The active LME has color while the others are grey.\n",
    "    if create_maps:\n",
    "        # Setup the figure panels\n",
    "        fig = plt.figure(figsize=(13, 8))\n",
    "        if LME in [\"Barents Sea\",\"Arctic Ocean\"]:\n",
    "            projection=ccrs.NorthPolarStereo() #ccrs.PlateCarree(central_longitude=0)\n",
    "            extent = [-20, 90, 60, 90]\n",
    "     #       extent = [-180, 180, 60, 90]\n",
    "        else:\n",
    "            projection=ccrs.PlateCarree(central_longitude=-180)\n",
    "            extent = [-252, -100, 10, 65]\n",
    "            extent = [-200, -145, 40, 80]\n",
    "        ax1 = fig.add_subplot(111, projection=projection)\n",
    "\n",
    "        create_LME_figure(ax1, [LME], ccrs.PlateCarree(central_longitude=-180),True,extent)\n",
    "\n",
    "    # Rioxarray requires x and y dimensions - we convert these back to lon and lat later.\n",
    "    # We also add the projection (lat-lon) so that rioxarray can do the clipping of the data according to the\n",
    "    # shapefile.\n",
    "\n",
    "    tos=ds.rename({'lon': 'x','lat': 'y'})\n",
    "    tos=tos.rio.write_crs(4326)\n",
    "\n",
    "    # Clip the data within the LME. We have to convert the polygon geometry to a geodataframe using\n",
    "    # `shapely.geometry`. The clipping of data within the polygon is done using rioxarray.clip function\n",
    "\n",
    "    clipped = tos.rio.clip(geometries=shdf_sel.geometry.apply(mapping), crs=tos.rio.crs)\n",
    "    clipped=clipped.rename({'x': 'lon','y': 'lat'}) #.to_dataset()\n",
    "\n",
    "    p1=\"2000-01-01 to 2020-01-01\"\n",
    "    p2=\"2080-01-01 to 2020-01-01\"\n",
    "\n",
    "    create_maps=False\n",
    "    if create_maps:\n",
    "        clipped_p1=clipped.sel(time=slice(\"2000-01-01\",\"2020-01-01\")).mean({\"time\"})\n",
    "       # clipped_p2=clipped.sel(time=slice(\"2080-01-01\",\"2099-12-16\")).mean({\"time\"})\n",
    "\n",
    "        create_map(clipped_p1, \"{} 2000-01-01 to 2020-01-01\".format(var_name), var_name, period=p1, anomalies=False, details=False)\n",
    "        #create_map(clipped_p2, \"{} 2080-01-01 to 2020-01-01\".format(var_name), var_name, period=p2, anomalies=False, details=False)\n",
    "\n",
    "        plt.show()\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_summary_table(dict_of_models, LME):\n",
    "    table = texttable.Texttable()\n",
    "    table.set_cols_align([\"c\",\"c\", \"c\",\"c\",\"c\",\"c\",\"c\"])\n",
    "    table.set_cols_valign([\"t\",\"t\", \"m\",\"m\",\"m\",\"m\", \"b\"])\n",
    "\n",
    "    table.header([\"LME\",\"Model\", \"Scenario\", \"ID\", \"Var\", \"CMIP6 min\", \"CMIP6 max\"])\n",
    "    for key in dict_of_models.keys():\n",
    "        model=dict_of_models[key]\n",
    "\n",
    "        table.add_row([LME,\n",
    "                       model[\"model_name\"],\n",
    "                       model[\"model_scenario\"],\n",
    "                       model[\"model_ensemble_id\"],\n",
    "                       str(model[\"model_var\"]),\n",
    "                       str(model[\"model_min\"]),\n",
    "                       str(model[\"model_max\"])])\n",
    "\n",
    "    table.set_cols_width([30,30,20,20,10,10,10])\n",
    "    print(table.draw() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on LME: Barents Sea\n",
      "Created dataframe of file: ../oceanography/cmip6/light/ssp245/CanESM5/CMIP6_CanESM5_r10i1p2f1_ssp245_chl.nc\n",
      "Working on LME: Barents Sea\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RangeIndex' object has no attribute '_with_freq'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m<timed exec>:68\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36mget_area_averaged_ds\u001B[0;34m(fname, model, scenario, ensemble_id, var_name, LME, create_maps, frequency, models_dict, fname2)\u001B[0m\n\u001B[1;32m     61\u001B[0m         df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[1;32m     62\u001B[0m         df\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muas\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvas\u001B[39m\u001B[38;5;124m\"\u001B[39m], inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 64\u001B[0m df\u001B[38;5;241m=\u001B[39m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfrequency\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtime\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_name\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m=\u001B[39mmodel\n\u001B[1;32m     66\u001B[0m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLME\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m=\u001B[39mLME\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/light/lib/python3.9/site-packages/pandas/core/resample.py:998\u001B[0m, in \u001B[0;36mg\u001B[0;34m(self, _method, *args, **kwargs)\u001B[0m\n\u001B[1;32m    996\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mg\u001B[39m(\u001B[38;5;28mself\u001B[39m, _method\u001B[38;5;241m=\u001B[39mmethod, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    997\u001B[0m     nv\u001B[38;5;241m.\u001B[39mvalidate_resampler_func(_method, args, kwargs)\n\u001B[0;32m--> 998\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_downsample\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_method\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/light/lib/python3.9/site-packages/pandas/core/resample.py:1131\u001B[0m, in \u001B[0;36mDatetimeIndexResampler._downsample\u001B[0;34m(self, how, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(ax):\n\u001B[1;32m   1129\u001B[0m     \u001B[38;5;66;03m# reset to the new freq\u001B[39;00m\n\u001B[1;32m   1130\u001B[0m     obj \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m-> 1131\u001B[0m     obj\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_with_freq\u001B[49m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfreq)\n\u001B[1;32m   1132\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m obj\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mfreq \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfreq, (obj\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mfreq, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfreq)\n\u001B[1;32m   1133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'RangeIndex' object has no attribute '_with_freq'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scenarios=[\"ssp245\",\"ssp585\"]\n",
    "member_range=10\n",
    "frequency=\"A\"\n",
    "ensemble_ids = [\"r{}i{}p{}f{}\".format(str(i + 1), str(ii + 1), str(iii + 1), str(iv + 1)) for i in\n",
    "                           range(member_range)\n",
    "                           for ii in range(member_range) for iii in range(member_range) for iv in range(member_range)]\n",
    "\n",
    "#ensemble_ids = [\"r10i1p1f1\", \"r4i1p1f1\", \"r10i1p2f1\", \"r3i1p2f1\", \"r2i1p1f2\",#\"r4i1p1f2\",\"r2i1p1f1\"]\n",
    "period=\"1950-01-01-2099-12-16\"\n",
    "start_time=\"1950-01-01\"\n",
    "end_time=\"2099-12-16\"\n",
    "\n",
    "models=[\"CanESM5\",\"CMCC-ESM2\",\"MPI-ESM1-2-HR\", \"ACCESS-ESM1-5\", \"MPI-ESM1-2-LR\"]\n",
    "ds_var_names=[\"velocity\",\"chl\", \"clt\", \"sithick\", \"siconc\", \"tas\",\"chl\"]\n",
    "ds_var_names=[\"chl\", \"clt\", \"sithick\", \"siconc\", \"tas\",\"chl\"]#[\"velocity\"]\n",
    "#ds_var_names=[\"clt\"]\n",
    "\n",
    "LMES=['California Current','East Bering Sea','Gulf of Alaska',\n",
    "      'Northern Bering - Chukchi Seas','West Bering Sea','Sea of Japan',\n",
    "      'Oyashio Current','Kuroshio Current','East China Sea',\n",
    "      'South China Sea','Sea of Okhotsk','Yellow Sea',\n",
    "      'Aleutian Islands']\n",
    "\n",
    "LMES=['Barents Sea','Northern Bering - Chukchi Seas']\n",
    "LMES=['Barents Sea','East Bering Sea','Northern Bering - Chukchi Seas']\n",
    "LMES=['Barents Sea','Northern Bering - Chukchi Seas']\n",
    "toz_list=[]\n",
    "\n",
    "for var_name in ds_var_names:\n",
    "    for LME in LMES:\n",
    "        df_list=[]\n",
    "        models_dict={}\n",
    "        create_maps=False\n",
    "        # We loop over all of the scenarios, ensemble_ids, and models to create a\n",
    "        # list of dataframes that we eventually concatenate together and plot\n",
    "        for scenario in scenarios:\n",
    "            ds_list=[]\n",
    "            for model in models:\n",
    "                for ensemble_id in ensemble_ids:\n",
    "                    if var_name in [\"TOZ\"]:\n",
    "                        fname = \"../oceanography/cmip6/light/ozone-absorption/TOZ_{}.nc\".format(scenario)\n",
    "                        fname2=None\n",
    "\n",
    "                    elif var_name not in [\"velocity\", \"TOZ\"]:\n",
    "                        fname = \"../oceanography/cmip6/light/{}/{}/CMIP6_{}_{}_{}_{}.nc\".format(scenario,model,\n",
    "                                                                                             model,\n",
    "                                                                                             ensemble_id,\n",
    "                                                                                             scenario,\n",
    "                                                                                             var_name)\n",
    "                        fname2=None\n",
    "                    elif var_name in [\"velocity\"]:\n",
    "                        fname = \"../oceanography/cmip6/light/{}/{}/CMIP6_{}_{}_{}_{}.nc\".format(scenario,model,\n",
    "                                                                                         model,\n",
    "                                                                                         ensemble_id,\n",
    "                                                                                         scenario,\n",
    "                                                                                         \"uas\")\n",
    "                        fname2 = \"../oceanography/cmip6/light/{}/{}/CMIP6_{}_{}_{}_{}.nc\".format(scenario,model,\n",
    "                                                                                         model,\n",
    "                                                                                         ensemble_id,\n",
    "                                                                                         scenario,\n",
    "                                                                                             \"vas\")\n",
    "                    key=\"{}_{}_{}_{}\".format(model,ensemble_id,scenario,var_name)\n",
    "                    if var_name in [\"TOZ\"]:\n",
    "                        key=fname\n",
    "\n",
    "                    if key not in models_dict.keys():\n",
    "\n",
    "                        df, models_dict, ds_lme = get_area_averaged_ds(fname, model,scenario, ensemble_id,var_name, LME, create_maps, frequency, models_dict,fname2)\n",
    "                        create_maps=False\n",
    "                        if ds_lme is not None:\n",
    "                          #  ds_lme=xr.where( ((ds_lme < 1.e-3)| (ds_lme > 1e3)), np.nan, ds_lme)\n",
    "                           # ds_lme=xr.where(ds_lme < 1, np.nan, ds_lme)\n",
    "                            ds_list.append(ds_lme)\n",
    "\n",
    "                        if df is not None:\n",
    "\n",
    "                            df_list.append(df)\n",
    "                            if var_name in [\"TOZ\"]:\n",
    "                                toz_list.append(df)\n",
    "                            print(\"Created dataframe of file: {}\".format(fname))\n",
    "\n",
    "            if len(ds_list) > 0:\n",
    "                ens = ensembles.create_ensemble(ds_list).load()\n",
    "                ens.close()\n",
    "                ens_stats = ensembles.ensemble_mean_std_max_min(ens)\n",
    "\n",
    "                outfile = \"Figures/{}_ensemble_{}_{}.png\".format(var_name.capitalize(),scenario, LME)\n",
    "\n",
    "             #   CMIP6_ridgeplot.ridgeplot(\"{}_mean\".format(var_name),\n",
    "             #                             None, outfile,\n",
    "             #                                     glorys=False, depth_threshold=None,\n",
    "             #                                     ds=ens_stats)\n",
    "\n",
    "\n",
    "        if len(df_list) > 0:\n",
    "            df = pd.concat(df_list)\n",
    "\n",
    "            create_summary_table(models_dict, LME)\n",
    "            df = df.reindex()\n",
    "            df[\"date\"]=df.index\n",
    "\n",
    "            if os.path.exists(\"test.csv\"):os.remove(\"test.csv\")\n",
    "            df.to_csv(\"test.csv\")\n",
    "            df = pd.read_csv('test.csv', parse_dates=['time', 'date'])\n",
    "\n",
    "            sns.set(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)}, font_scale=1.5)\n",
    "            f=plt.figure(figsize=(16, 16))\n",
    "            gs = f.add_gridspec(2, 1)\n",
    "            ax = f.add_subplot(gs[0, 0])\n",
    "\n",
    "            sns.set_palette(\"tab10\")\n",
    "            legend_on=True if var_name==\"tas\" else False\n",
    "\n",
    "            b=sns.lineplot(ax=ax, data=df, x=df[\"date\"], y=df[\"roll_mean\"],\n",
    "                         hue=df[\"model_scenario\"],\n",
    "                         alpha=.95, ci=95,linewidth=5, legend=legend_on)\n",
    "            b.tick_params(labelsize=22)\n",
    "            b.set_xlabel(\"\",fontsize=20)\n",
    "            b.set_ylabel(\"\",fontsize=20)\n",
    "            import matplotlib.dates as mdates\n",
    "            if var_name==\"tas\":\n",
    "                plt.legend(loc=\"upper left\", frameon=False, fontsize=32)\n",
    "\n",
    "            ax.xaxis.set_major_locator(mdates.YearLocator(base=10))\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "            plt.setp(ax.xaxis.get_majorticklabels(), rotation=-90)\n",
    "\n",
    "            if not os.path.exists(\"Figures\"):\n",
    "                os.makedirs(\"Figures\")\n",
    "            plotfile=\"Figures/CMIP6_lightpaper_{}_{}.png\".format(var_name,LME)\n",
    "            print(\"Created figure {}\".format(plotfile))\n",
    "            plt.savefig(plotfile, dpi=300,\n",
    "                        bbox_inches = 'tight')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        df=pd.DataFrame()\n",
    "        ds_list=[]\n",
    "\n",
    "    if var_name in [\"TOZ\"]:\n",
    "        df = pd.concat(toz_list)\n",
    "\n",
    "        sns.set(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)}, font_scale=1.5)\n",
    "        f=plt.figure(figsize=(16, 16))\n",
    "        gs = f.add_gridspec(2, 1)\n",
    "        ax = f.add_subplot(gs[0, 0])\n",
    "\n",
    "        sns.set_palette(\"tab10\")\n",
    "        b=sns.lineplot(ax=ax, data=df, x=df.index, y=df[\"roll_mean\"],\n",
    "                     hue=\"LME\",\n",
    "                     alpha=.9, ci=95,linewidth=4)\n",
    "        b.tick_params(labelsize=20)\n",
    "        b.set_xlabel(\"\",fontsize=18)\n",
    "        b.set_ylabel(\"\",fontsize=18)\n",
    "\n",
    "        plt.legend(loc=\"upper right\", frameon=False, fontsize=20)\n",
    "\n",
    "        if not os.path.exists(\"Figures\"):\n",
    "            os.makedirs(\"Figures\")\n",
    "        plotfile=\"Figures/CMIP6_lightpaper_{}_{}.png\".format(var_name,LME)\n",
    "        print(\"Created figure {}\".format(plotfile))\n",
    "      #  plt.savefig(plotfile, dpi=300,\n",
    "      #              bbox_inches = 'tight')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-36b96e94",
   "language": "python",
   "display_name": "PyCharm (cmip6-albedo)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}