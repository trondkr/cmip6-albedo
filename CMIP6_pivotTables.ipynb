{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gcsfs\n",
    "import sys\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/xesmf2/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://cmip6.storage.googleapis.com/cmip6-zarr-consolidated-stores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple search on keywords\n",
    "def search_df(df, verbose= False, **search):\n",
    "    \"search by keywords - if list, then match exactly, otherwise match as substring\"\n",
    "    keys = ['activity_id','institution_id','source_id','experiment_id','member_id', 'table_id', 'variable_id', 'grid_label']\n",
    "    d = df\n",
    "    for skey in search.keys():\n",
    "        \n",
    "        if isinstance(search[skey], str):  # match a string as a substring\n",
    "            d = d[d[skey].str.contains(search[skey])]\n",
    "        else:\n",
    "            dk = []\n",
    "            for key in search[skey]:       # match a list of strings exactly\n",
    "                dk += [d[d[skey]==key]]\n",
    "            d = pd.concat(dk)\n",
    "            keys.remove(skey)\n",
    "    if verbose:\n",
    "        for key in keys:\n",
    "            print(key,' = ',list(d[key].unique()))      \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfp = search_df(df, experiment_id=['historical','ssp585'], table_id=['Omon','Amon'], variable_id=[\"uas\",\"vas\",\"tos\"], grid_label=['gr'])\n",
    "dfp = search_df(df, experiment_id=['historical','ssp585'],table_id=[\"SImon\", \"SImon\",\"SImon\",\"SImon\"],\n",
    "                variable_id=[\"sithick\", \"siconc\", \"sisnthick\", \"sisnconc\"], grid_label=['gn'])\n",
    "#dfp = search_df(df, experiment_id=['historical','ssp585'], member_id=['r1i1p1f1'],table_id=['Amon','SImon','Omon','Amon'], variable_id=[\"uas\",\"vas\",\"chl\",\"clt\"], grid_label=['gn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable_id                   siconc  sisnconc  sisnthick  sithick\n",
      "experiment_id source_id                                           \n",
      "historical    ACCESS-ESM1-5       11        11         11       11\n",
      "              AWI-CM-1-1-MR        0         5          5        5\n",
      "              AWI-ESM-1-1-LR       1         1          1        1\n",
      "              BCC-CSM2-MR          3         0          3        0\n",
      "              BCC-ESM1             3         0          3        0\n",
      "...                              ...       ...        ...      ...\n",
      "ssp585        MRI-ESM2-0           1         0          0        0\n",
      "              NESM3                2         0          2        2\n",
      "              NorESM2-LM           1         1          1        1\n",
      "              NorESM2-MM           1         1          1        1\n",
      "              UKESM1-0-LL          5         5          5        5\n",
      "\n",
      "[82 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "dm = dfp[['experiment_id','source_id','variable_id','member_id',]].groupby(['experiment_id','source_id','variable_id']).nunique()[['member_id']]\n",
    "\n",
    "table = pd.DataFrame.pivot_table(dm, values='member_id', index=['experiment_id','source_id'],\n",
    "                                 columns=['variable_id'], aggfunc=np.sum, fill_value=0)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         member_id\n",
      "experiment_id source_id     variable_id           \n",
      "historical    ACCESS-ESM1-5 siconc              11\n",
      "                            sisnconc            11\n",
      "                            sisnthick           11\n",
      "                            sithick             11\n",
      "              AWI-CM-1-1-MR sisnconc             5\n",
      "...                                            ...\n",
      "ssp585        NorESM2-MM    sithick              1\n",
      "              UKESM1-0-LL   siconc               5\n",
      "                            sisnconc             5\n",
      "                            sisnthick            5\n",
      "                            sithick              5\n",
      "\n",
      "[256 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#table[(table.uas>0)&(table.vas>0)&(table.chl>0)&(table.clt>0)&(table.sisnconc>0)&(table.sisnthick>0)&(table.siconc>0)&(table.sithick>0)]\n",
    "table[(table.sithick>0)&(table.siconc>0)&(table.sisnconc>0)&(table.sisnthick>0)]\n",
    "print(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_organize_cmip6_data(conf):\n",
    "    # Dictionary to hold the queried variables\n",
    "    first = True\n",
    "    for experiment_id in conf.experiment_ids:\n",
    "        for grid_label in conf.grid_labels:\n",
    "            for source_id in conf.source_ids:\n",
    "                for member_id in conf.member_ids:\n",
    "                    for variable_id, table_id in zip(conf.variable_ids, conf.table_ids):\n",
    "                        \n",
    "                        # Create unique key to hold dataset in dictionary\n",
    "                        key=\"{}_{}_{}_{}_{}\".format(variable_id,experiment_id,grid_label,source_id,member_id)\n",
    "                        # Historical query string\n",
    "                        query_string = \"source_id=='{}'and table_id=='{}' and grid_label=='{}' and experiment_id=='historical' and variable_id=='{}'\".format(source_id, \n",
    "                        table_id, \n",
    "                        grid_label,\n",
    "                        variable_id)\n",
    "                        \n",
    "                        print(\n",
    "                            \"Running historical query on data: \\n ==> {}\\n\".format(query_string)\n",
    "                        )\n",
    "                        ds_hist = perform_cmip6_query(conf,query_string)\n",
    "                       \n",
    "                        # Future projection depending on choice in experiment_id\n",
    "                        query_string = \"source_id=='{}'and table_id=='{}' and member_id=='{}' and grid_label=='{}' and experiment_id=='{}' and variable_id=='{}'\".format(\n",
    "                                source_id,\n",
    "                                table_id,\n",
    "                                member_id,\n",
    "                                grid_label,\n",
    "                                experiment_id,\n",
    "                                variable_id,\n",
    "                            )\n",
    "                            print(\n",
    "                                \"Running projections query on data: \\n ==> {}\\n\".format(\n",
    "                                    query_string\n",
    "                                )\n",
    "                            )\n",
    "                        ds_proj = perform_cmip6_query(conf,query_string)\n",
    "\n",
    "                        if first:\n",
    "                            df_area = conf.df.query(\n",
    "                                    \"variable_id == 'areacella' and source_id =='{}'\".format(\n",
    "                                        source_id\n",
    "                                    )\n",
    "                                )\n",
    "                            ds_area = xr.open_zarr(\n",
    "                                    conf.fs.get_mapper(df_area.zstore.values[0]), consolidated=True\n",
    "                                )\n",
    "                            first = False\n",
    "\n",
    "                        # Concatentate the historical and projections datasets\n",
    "                    #    ds_hist=ds_hist.sel(time=slice(ds_hist[\"time\"][0],\"2000-12-15\"))\n",
    "                        #  print(\"Time in projection {} - {}\".format(ds_proj[\"time\"][0],ds_proj[\"time\"][-1]))\n",
    "                        ds = xr.concat([ds_hist, ds_proj], dim=\"time\")\n",
    "\n",
    "                        # Remove the duplicate overlapping times (e.g. 2001-2014)\n",
    "                        #  _, index = np.unique(ds[\"time\"], return_index=True)\n",
    "                        #  ds = ds.isel(time=index)\n",
    "\n",
    "                        # Extract the time period of interest\n",
    "                        ds=ds.sel(time=slice(conf.start_date,conf.end_date))\n",
    "                        print(\"{} => Dates extracted range from {} to {}\\n\".format(source_id,ds[\"time\"].values[0], ds[\"time\"].values[-1]))\n",
    "\n",
    "                        # Save the dataset for variable_id in the dictionary\n",
    "                        conf.dset_dict[key] = ds\n",
    "\n",
    "def perform_cmip6_query(conf,query_string):\n",
    "    df_sub = conf.df.query(query_string)\n",
    "    if (df_sub.zstore.values.size==0):\n",
    "        return df_sub\n",
    "    \n",
    "    mapper = conf.fs.get_mapper(df_sub.zstore.values[-1])\n",
    "    ds = xr.open_zarr(mapper, consolidated=True)\n",
    "\n",
    "    time_object = ds[\"time\"].values[0]\n",
    "    \n",
    "    # Convert if necesssary\n",
    "    if time_object.year == 1:\n",
    "        \n",
    "        times = ds[\"time\"].values\n",
    "        times_plus_2000 = []\n",
    "        for t in times:\n",
    "            times_plus_2000.append(\n",
    "                cftime.DatetimeNoLeap(t.year + 2000, t.month, t.day, t.hour)\n",
    "            )\n",
    "        ds[\"time\"].values = times_plus_2000\n",
    "        ds = xr.decode_cf(ds)                    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config_pices():\n",
    "    df = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv\"\n",
    ")\n",
    "    fs = gcsfs.GCSFileSystem(token=\"anon\", access=\"read_only\")\n",
    "   \n",
    "    grid_labels = [\"gr\"]  # Can be gr=grid rotated, or gn=grid native\n",
    "    member_ids = [\"r1i1p1f1\"]  #\n",
    "    experiment_ids = [\"ssp585\"]  #'abrupt-4xCO2',\n",
    "    source_ids = [\"KACE-1-0-G\"]\n",
    "    variable_ids = [\"tos\",\"uas\",\"vas\"]\n",
    "    table_ids = [\"Omon\",\"Amon\",\"Amon\"]  # Amon=atmospheric variables, Omon=Ocean variables, SImon=sea-ice variables\n",
    "    dset_dict = {}\n",
    "    start_date=\"1900-01-01\"\n",
    "    end_date=\"2100-08-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_pices_obj=Config_pices()\n",
    "get_and_organize_cmip6_data(config_pices_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}