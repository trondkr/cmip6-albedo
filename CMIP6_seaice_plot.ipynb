{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import cdsapi\n",
    "import numpy as np\n",
    "import warnings\n",
    "import regionmask\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "import cftime\n",
    "import os\n",
    "import seaborn as sns\n",
    "import cartopy\n",
    "import cartopy.feature as cpf\n",
    "from global_land_mask import globe\n",
    "import CMIP6_light_map\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from shapely.geometry import box, mapping\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "from matplotlib import cm\n",
    "import cartopy.feature as cpf\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import texttable\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_180(ds):\n",
    "    ds=ds.assign_coords(lat=ds.y)\n",
    "    return (ds.assign_coords(lon=(((ds.x + 180) % 360) - 180))).sortby('lon')\n",
    "\n",
    "def convert_time(ds):\n",
    "    if not ds.indexes[\"time\"].dtype in [\"datetime64[ns]\"]:\n",
    "\n",
    "        time_objects = ds.indexes['time'].to_datetimeindex() \n",
    "        ds=ds.assign_coords({\"time\": time_objects})                   \n",
    "        ds = xr.decode_cf(ds)\n",
    "        \n",
    "    return ds\n",
    "\n",
    "def get_area_averaged_ds(fname, model, scenario, ensemble_id, var_name, LME, create_maps, frequency, models_dict):\n",
    "    \n",
    "    if os.path.exists(fname):\n",
    "        with xr.open_dataset(fname) as ds:\n",
    "            ds = convert_to_180(ds)\n",
    "            ds = ds.sel(time=slice(start_time,end_time)) #.sel(lat=slice(min_lat,max_lat), lon=slice(min_lon,max_lon))\n",
    "            ds = convert_time(ds)\n",
    "            ds = get_data_within_LME(ds, var_name, LME, create_maps)\n",
    "            ds = ds.mean({\"lat\",\"lon\"})\n",
    "            df = ds.to_dataframe().dropna()\n",
    "            \n",
    "            df = df.reset_index()\n",
    "         #   df['time'] = pd.to_datetime(df['time'])\n",
    "            \n",
    "            df=df.resample(frequency, on=\"time\").mean()\n",
    "            df[\"model_name\"]=model\n",
    "            df[\"model_ensemble_id\"]=ensemble_id\n",
    "            df[\"model_scenario\"]=scenario\n",
    "            unique=\"{}_{}_{}\".format(model, scenario, ensemble_id)\n",
    "            df[\"unique\"]=unique\n",
    "\n",
    "            model_info={}\n",
    "            model_info[\"model_name\"]=model\n",
    "            model_info[\"model_scenario\"]=scenario\n",
    "            model_info[\"model_ensemble_id\"]=ensemble_id\n",
    "            model_info[\"model_var\"]=var_name\n",
    "            key=\"{}_{}_{}_{}\".format(model,ensemble_id,scenario,var_name)\n",
    "            formatter=\"{:.2f}\"\n",
    "            model_info[\"model_min\"]=formatter.format(np.nanmin(df[var_name]))\n",
    "            model_info[\"model_max\"]=formatter.format(np.nanmax(df[var_name]))\n",
    "\n",
    "            models_dict[key]=model_info\n",
    "\n",
    "            return df, models_dict\n",
    "    else:\n",
    "        return None, models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_LME_records():\n",
    "    lme_file='../oceanography/Shapefiles/LME66/LMEs66.shp'\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "def get_LME_records_plot():\n",
    "    lme_file='../oceanography/Shapefiles/LME66_180/LME66_180.shp'\n",
    "    return gpd.read_file(lme_file)\n",
    "\n",
    "def create_colors(N):\n",
    "    color=iter(cm.tab20b(np.linspace(0,1,N)))\n",
    "    return [next(color) for c in range(N)]\n",
    "\n",
    "def create_map(df, title, var_name, period, anomalies=False, details=False):\n",
    "    if details is True:\n",
    "        lonmin=-165\n",
    "        lonmax=-143.5\n",
    "        latmin=53.5\n",
    "        latmax=65.0\n",
    "        res=\"10m\"\n",
    "    else:\n",
    "        lonmin=-252\n",
    "        lonmax=-100.5\n",
    "        latmin=20\n",
    "        latmax=80\n",
    "        res=\"50m\"\n",
    "    ax = plt.figure(figsize=(16,10)).gca(projection=cartopy.crs.PlateCarree(central_longitude=-180))\n",
    "\n",
    "    ax.coastlines(resolution=res, linewidth=0.6, color=\"black\", alpha=0.8, zorder=4)\n",
    "    ax.add_feature(cpf.BORDERS, linestyle=':',alpha=0.4)\n",
    "    ax.add_feature(cpf.LAND, color=\"lightgrey\")\n",
    "    ax.set_extent([lonmin, lonmax, latmin, latmax])\n",
    "\n",
    "    xticks = np.linspace(lonmin, lonmax, 5)\n",
    "    yticks = np.linspace(latmin, latmax, 5)\n",
    "\n",
    "    ax.set_xticks(xticks, crs=cartopy.crs.PlateCarree())\n",
    "    ax.set_yticks(yticks, crs=cartopy.crs.PlateCarree())\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)\n",
    "\n",
    "    #if var_name in [\"par\"]:\n",
    "    clb_label='PAR ($W/m^{2}$)'\n",
    "    cs=ax.contourf(df[\"lon\"], df[\"lat\"], df[var_name], #np.where(df[\"H\"] < 0, df[\"H\"], np.nan), # df[var_name],\n",
    "                   cmap=sns.color_palette(\"Spectral_r\", as_cmap=True),\n",
    "                   transform=ccrs.PlateCarree())\n",
    "\n",
    "    if title not in [\"Bathymetry\"]:\n",
    "        clb = plt.colorbar(cs, shrink=0.5, extend=\"both\")\n",
    "\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "\n",
    "    #if details:\n",
    "    #    plt.savefig(\"../../GOA-Laurel/Figures/Bottom_{}_july_sept_250m_zoomed_{}.png\".format(var_name, period), dpi=300,\n",
    "    #                facecolor='w',\n",
    "    #                transparent=False,\n",
    "    #                bbox_inches = 'tight',\n",
    "    #                pad_inches = 0)\n",
    "    #else:\n",
    "    #    plt.savefig(\"../../GOA-Laurel/Figures/Bottom_{}_july_sept_250m_{}.png\".format(var_name, period), dpi=300,\n",
    "    #            facecolor='w',\n",
    "    #                transparent=False,\n",
    "    #                bbox_inches = 'tight',\n",
    "    #                pad_inches = 0)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_LME_figure(ax, LMES, projection, show):\n",
    "\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    extent = [-252, -100, 10, 65]\n",
    "    ax.set_extent(extent)\n",
    "\n",
    "    # Get the -180-180 projected shapefile containing LMEs to make it\n",
    "    # easy to plot across the Pacific Ocean\n",
    "    shdf = get_LME_records_plot()\n",
    "    colors_rgb=create_colors(len(LMES))\n",
    "    counter=0\n",
    "    for LME_NAME,LME_NUMBER in zip(shdf['LME_NAME'],shdf['LME_NUMBER']):\n",
    "\n",
    "        shdf_sel = shdf[ shdf['LME_NAME']==LME_NAME ]\n",
    "\n",
    "        if (LME_NAME in LMES):\n",
    "            print(\"Adding geometry for LME {}\".format(LME_NAME))\n",
    "            # Add the geometry and fill it with color\n",
    "            if len(LMES)==1:\n",
    "                color=\"red\"\n",
    "            else:\n",
    "                color=colors_rgb[counter]\n",
    "            ax.add_geometries(shdf_sel['geometry'],\n",
    "                              projection,\n",
    "                              facecolor=color,\n",
    "                              edgecolor='k')\n",
    "\n",
    "            # Add the label LME_NUMBER of the selected LME at the center of the LME\n",
    "            ax.annotate(s=LME_NUMBER,\n",
    "                        xy=(shdf_sel.centroid.x,shdf_sel.centroid.y),\n",
    "                        color=\"white\",\n",
    "                        fontsize=13)\n",
    "            counter+=1\n",
    "        else:\n",
    "            ax.add_geometries(shdf_sel['geometry'],\n",
    "                              projection,\n",
    "                              facecolor='LightGray',\n",
    "                              edgecolor='k')\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "def get_data_within_LME(ds,var_name,LME,create_maps):\n",
    "\n",
    "    print(\"Working on LME: {}\".format(LME))\n",
    "    \n",
    "    # Extract the polygon defining the boundaries of the LME\n",
    "    shdf = get_LME_records()\n",
    "  #  for name in shdf['LME_NAME']:\n",
    "  #      print(name)\n",
    "    shdf_sel = shdf[ shdf['LME_NAME']==LME ]\n",
    "\n",
    "    # Create the map of the LME bopundaries and color it.\n",
    "    # The active LME has color while the others are grey.\n",
    "    if create_maps:\n",
    "        # Setup the figure panels\n",
    "        fig = plt.figure(figsize=(13, 8))\n",
    "        projection=ccrs.PlateCarree(central_longitude=-180)\n",
    "        ax1 = fig.add_subplot(111, projection=projection)\n",
    "    \n",
    "        create_LME_figure(ax1, [LME], projection,False)\n",
    "\n",
    "    # We need to add the projection to the dataset. Lon and lat projections are WGS84 (epsg:4326)\n",
    " \n",
    " #   ds.coords['x'] = (ds.coords['x'] + 180) % 360 - 180\n",
    " #   ds = ds.sortby(ds.x)\n",
    "\n",
    "    # Rioxarray requires x and y dimensions - we convert these back to lon and lat later.\n",
    "    # We also add the projection (lat-lon) so that rioxarray can do the clipping of the data according to the\n",
    "    # shapefile.\n",
    "\n",
    "    tos=ds.rename({'lon': 'x','lat': 'y'})\n",
    "    tos=tos.rio.write_crs(4326)\n",
    "\n",
    "    # Clip the data within the LME. We have to convert the polygon geometry to a geodataframe using\n",
    "    # `shapely.geometry`. The clipping of data within the polygon is done using rioxarray.clip function\n",
    "\n",
    "    clipped = tos.rio.clip(geometries=shdf_sel.geometry.apply(mapping), crs=tos.rio.crs)\n",
    "    clipped=clipped.rename({'x': 'lon','y': 'lat'}) #.to_dataset()\n",
    "\n",
    "    p1=\"2000-01-01 to 2020-01-01\"\n",
    "    p2=\"2080-01-01 to 2020-01-01\"\n",
    "\n",
    "    create_maps=False\n",
    "    if create_maps:\n",
    "        clipped_p1=clipped.sel(time=slice(\"2000-01-01\",\"2020-01-01\")).mean({\"time\"})\n",
    "       # clipped_p2=clipped.sel(time=slice(\"2080-01-01\",\"2099-12-16\")).mean({\"time\"})\n",
    "\n",
    "        create_map(clipped_p1, \"{} 2000-01-01 to 2020-01-01\".format(var_name), var_name, period=p1, anomalies=False, details=False)\n",
    "        #create_map(clipped_p2, \"{} 2080-01-01 to 2020-01-01\".format(var_name), var_name, period=p2, anomalies=False, details=False)\n",
    "\n",
    "        plt.show()\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_summary_table(dict_of_models, LME):\n",
    "    table = texttable.Texttable()\n",
    "    table.set_cols_align([\"c\",\"c\", \"c\",\"c\",\"c\",\"c\",\"c\"])\n",
    "    table.set_cols_valign([\"t\",\"t\", \"m\",\"m\",\"m\",\"m\", \"b\"])\n",
    "\n",
    "    table.header([\"LME\",\"Model\", \"Scenario\", \"ID\", \"Var\", \"CMIP6 min\", \"CMIP6 max\"])\n",
    "    for key in dict_of_models.keys():\n",
    "        model=dict_of_models[key]\n",
    "\n",
    "        table.add_row([LME,\n",
    "                       model[\"model_name\"],\n",
    "                       model[\"model_scenario\"],\n",
    "                       model[\"model_ensemble_id\"],\n",
    "                       str(model[\"model_var\"]),\n",
    "                       str(model[\"model_min\"]),\n",
    "                       str(model[\"model_max\"])])\n",
    "\n",
    "\n",
    "\n",
    "    table.set_cols_width([30,30,20,20,10,10,10])\n",
    "    print(table.draw() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on LME: Northern Bering - Chukchi Seas\n",
      "Adding geometry for LME Northern Bering - Chukchi Seas\n",
      "Created dataframe of file: ../oceanography/cmip6/light/ssp245/MPI-ESM1-2-HR/CMIP6_MPI-ESM1-2-HR_r1i1p1f1_ssp245_clt.nc\n",
      "Working on LME: Northern Bering - Chukchi Seas\n",
      "Created dataframe of file: ../oceanography/cmip6/light/ssp245/CanESM5/CMIP6_CanESM5_r1i1p1f1_ssp245_clt.nc\n",
      "Working on LME: Northern Bering - Chukchi Seas\n",
      "Created dataframe of file: ../oceanography/cmip6/light/ssp245/ACCESS-ESM1-5/CMIP6_ACCESS-ESM1-5_r1i1p1f1_ssp245_clt.nc\n",
      "Working on LME: Northern Bering - Chukchi Seas\n",
      "Created dataframe of file: ../oceanography/cmip6/light/ssp245/MPI-ESM1-2-LR/CMIP6_MPI-ESM1-2-LR_r1i1p1f1_ssp245_clt.nc\n",
      "Working on LME: Northern Bering - Chukchi Seas\n",
      "Created dataframe of file: ../oceanography/cmip6/light/ssp585/MPI-ESM1-2-HR/CMIP6_MPI-ESM1-2-HR_r1i1p1f1_ssp585_clt.nc\n",
      "Working on LME: Northern Bering - Chukchi Seas\n",
      "Created dataframe of file: ../oceanography/cmip6/light/ssp585/CanESM5/CMIP6_CanESM5_r1i1p1f1_ssp585_clt.nc\n",
      "Working on LME: Northern Bering - Chukchi Seas\n",
      "Created dataframe of file: ../oceanography/cmip6/light/ssp585/ACCESS-ESM1-5/CMIP6_ACCESS-ESM1-5_r1i1p1f1_ssp585_clt.nc\n",
      "Working on LME: Northern Bering - Chukchi Seas\n",
      "Created dataframe of file: ../oceanography/cmip6/light/ssp585/MPI-ESM1-2-LR/CMIP6_MPI-ESM1-2-LR_r1i1p1f1_ssp585_clt.nc\n",
      "+--------------------------------+--------------------------------+----------------------+----------------------+------------+------------+------------+\n",
      "|              LME               |             Model              |       Scenario       |          ID          |    Var     | CMIP6 min  | CMIP6 max  |\n",
      "+================================+================================+======================+======================+============+============+============+\n",
      "| Northern Bering - Chukchi Seas |         MPI-ESM1-2-HR          |        ssp245        |       r1i1p1f1       |    clt     |   77.320   |   87.210   |\n",
      "+--------------------------------+--------------------------------+----------------------+----------------------+------------+------------+------------+\n",
      "| Northern Bering - Chukchi Seas |            CanESM5             |        ssp245        |       r1i1p1f1       |    clt     |   75.100   |   84.970   |\n",
      "+--------------------------------+--------------------------------+----------------------+----------------------+------------+------------+------------+\n",
      "| Northern Bering - Chukchi Seas |         ACCESS-ESM1-5          |        ssp245        |       r1i1p1f1       |    clt     |   88.570   |   93.530   |\n",
      "+--------------------------------+--------------------------------+----------------------+----------------------+------------+------------+------------+\n",
      "| Northern Bering - Chukchi Seas |         MPI-ESM1-2-LR          |        ssp245        |       r1i1p1f1       |    clt     |   76.790   |   86.030   |\n",
      "+--------------------------------+--------------------------------+----------------------+----------------------+------------+------------+------------+\n",
      "| Northern Bering - Chukchi Seas |         MPI-ESM1-2-HR          |        ssp585        |       r1i1p1f1       |    clt     |   77.320   |   87.210   |\n",
      "+--------------------------------+--------------------------------+----------------------+----------------------+------------+------------+------------+\n",
      "| Northern Bering - Chukchi Seas |            CanESM5             |        ssp585        |       r1i1p1f1       |    clt     |   75.100   |   84.970   |\n",
      "+--------------------------------+--------------------------------+----------------------+----------------------+------------+------------+------------+\n",
      "| Northern Bering - Chukchi Seas |         ACCESS-ESM1-5          |        ssp585        |       r1i1p1f1       |    clt     |   88.570   |   93.530   |\n",
      "+--------------------------------+--------------------------------+----------------------+----------------------+------------+------------+------------+\n",
      "| Northern Bering - Chukchi Seas |         MPI-ESM1-2-LR          |        ssp585        |       r1i1p1f1       |    clt     |   76.790   |   86.030   |\n",
      "+--------------------------------+--------------------------------+----------------------+----------------------+------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scenarios=[\"ssp245\",\"ssp585\"]\n",
    "member_range=1\n",
    "frequency=\"A\"\n",
    "ensemble_ids = [\"r{}i{}p{}f{}\".format(str(i + 1), str(ii + 1), str(iii + 1), str(iv + 1)) for i in\n",
    "                           range(member_range)\n",
    "                           for ii in range(member_range) for iii in range(member_range) for iv in range(member_range)]\n",
    "period=\"1950-01-01-2099-12-16\"\n",
    "start_time=\"1950-01-01\"\n",
    "end_time=\"2099-12-16\"\n",
    "\n",
    "models=[\"MPI-ESM1-2-HR\",\"CanESM5\",\"ACCESS-ESM1-5\",\"MPI-ESM1-2-LR\",\"CanESM5-CanOE\",\"UKESM1-O-LL\"]\n",
    "ds_var_names=[\"clt\"]\n",
    "\n",
    "LMES=['California Current','East Bering Sea','Gulf of Alaska',\n",
    "      'Northern Bering - Chukchi Seas','West Bering Sea','Sea of Japan',\n",
    "      'Oyashio Current','Kuroshio Current','East China Sea',\n",
    "      'South China Sea','Sea of Okhotsk','Yellow Sea',\n",
    "      'Aleutian Islands']\n",
    "\n",
    "LMES=['Northern Bering - Chukchi Seas','Barents Sea']\n",
    "\n",
    "for var_name in ds_var_names:\n",
    "    for LME in LMES:\n",
    "        ds_list=[]\n",
    "        models_dict={}\n",
    "        create_maps=True\n",
    "        # We loop over all of the scenarios, ensemble_ids, and models to create a\n",
    "        # list of dataframes that we eventually concatenate together and plot\n",
    "        for scenario in scenarios:\n",
    "            for model in models:\n",
    "                for ensemble_id in ensemble_ids:\n",
    "                    fname = \"../oceanography/cmip6/light/{}/{}/CMIP6_{}_{}_{}_{}.nc\".format(scenario,model,\n",
    "                                                                                         model,\n",
    "                                                                                         ensemble_id,\n",
    "                                                                                         scenario,\n",
    "                                                                                         var_name)\n",
    "                    \n",
    "                    df, models_dict  = get_area_averaged_ds(fname, model,scenario, ensemble_id,var_name, LME, create_maps, frequency, models_dict)\n",
    "                    create_maps=False\n",
    "                    if df is not None:\n",
    "                       \n",
    "                        ds_list.append(df)\n",
    "                        print(\"Created dataframe of file: {}\".format(fname))\n",
    "                        \n",
    "\n",
    "        if len(ds_list) > 0:\n",
    "            df = pd.concat(ds_list)\n",
    "         \n",
    "            create_summary_table(models_dict, LME)\n",
    "\n",
    "            sns.set_style(\"ticks\")\n",
    "            f=plt.figure(figsize=(16, 16), dpi=150)\n",
    "            gs = f.add_gridspec(2, 1)\n",
    "            ax = f.add_subplot(gs[0, 0])\n",
    "\n",
    "            sns.set_palette(\"tab10\")\n",
    "         #   sns.lineplot(ax=ax, data=df, x=df.index, y=df[var_name], ci=95, alpha=0.95)\n",
    "\n",
    "            sns.lineplot(ax=ax, data=df, x=df.index, y=df[var_name],\n",
    "                         hue=df[\"model_scenario\"],\n",
    "                                     palette=\"crest\", alpha=.5, ci=15,linewidth=2)\n",
    "            plt.legend()\n",
    "            plt.ylabel(\"{}\".format(var_name))\n",
    "            if not os.path.exists(\"Figures\"):\n",
    "                os.makedirs(\"Figures\")\n",
    "            plotfile=\"Figures/CMIP6_lightpaper_{}.png\".format(var_name)\n",
    "            print(\"Created figure {}\".format(plotfile))\n",
    "            plt.savefig(plotfile, dpi=150,\n",
    "                        bbox_inches = 'tight')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        df=pd.DataFrame()\n",
    "        ds_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}